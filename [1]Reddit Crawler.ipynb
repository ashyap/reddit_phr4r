{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import Constants\n",
    "import csv\n",
    "import os \n",
    "import requests \n",
    "import datetime as dt\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['a', 'b', 'c']\n",
    "res = {\n",
    "    'a': 1,\n",
    "    'b': 2\n",
    "}\n",
    "[res[col] if col in res.keys() else None for col in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL = \"https://api.pushshift.io/reddit/submission/search/?after=1483228800&before=1577836800&sort_type=score&sort=desc&subreddit=phr4r&size=20\"\n",
    "URL = \"https://api.pushshift.io/reddit/submission/search/\"\n",
    "PARAMS = {\n",
    "    'after': 1483228800,\n",
    "    'before': 1577836800,\n",
    "    'sort_type': 'score',\n",
    "    'sort': 'desc',\n",
    "    'subreddit': 'phr4r',\n",
    "    'size': 20,\n",
    "    'fields': [\"id\",\"title\",\"selftext\",\"score\",\"num_comments\",\"created_utc\"]\n",
    "}\n",
    "r = requests.get(url = URL, params=PARAMS)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = dt.datetime.strptime(\"2011-12-12\", \"%Y-%m-%d\")\n",
    "date += dt.timedelta(days=1)\n",
    "timestamp = date.replace(tzinfo=dt.timezone.utc).timestamp()\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime.strptime(\"2011-12-1\", \"%Y-%m-%d\")\n",
    "end_date = dt.datetime.strptime(\"2011-12-31\", \"%Y-%m-%d\")\n",
    "(end_date - start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start_date, periods=(end_date - start_date).days).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start_date, periods=(end_date - start_date).days).tolist()\n",
    "for i, s_date in enumerate(date_range):\n",
    "    if i != len(date_range) -1:\n",
    "        print(i, s_date, date_range[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditPost:\n",
    "    def __init__(self, dict_obj):\n",
    "        for key in dict_obj.keys():\n",
    "            setattr(self, key, dict_obj[key])\n",
    "            \n",
    "class RedditCsvWriter:\n",
    "    def __init__(self, filename):\n",
    "        self.columns = [\"id\", \"title\", \"selftext\", \"num_comments\", \n",
    "                        \"score\", \"created_utc\"]\n",
    "        self.crawled_ids = []\n",
    "        if os.path.isfile(filename):\n",
    "            print(f\"{filename} exists, getting ids that have been crawled\")\n",
    "            self.file = open(filename, mode='a', encoding='utf-8')\n",
    "            self.file_writer = csv.writer(self.file, delimiter=',')\n",
    "            \n",
    "            temp_df = pd.read_csv(filename)\n",
    "            self.crawled_ids = temp_df[\"id\"].values.tolist()\n",
    "        else:\n",
    "            print(f\"{filename} does NOT exist, creating file\")\n",
    "            self.file = open(filename, mode='w', encoding='utf-8')\n",
    "            self.file_writer = csv.writer(self.file, delimiter=',')\n",
    "            self.file_writer.writerow(self.columns)\n",
    "            \n",
    "        \n",
    "    def write_submissions(self, submissions):\n",
    "        for submission in submissions[\"data\"]:\n",
    "            if submission[\"id\"] not in self.crawled_ids: \n",
    "                self.file_writer.writerow([submission[col] for col in self.columns])\n",
    "                self.crawled_ids.append(submission[\"id\"])\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.file.close()\n",
    "        \n",
    "class SubRedditCrawler:\n",
    "    def __init__(self, sub, start_date=\"2017-01-01\", \n",
    "                 end_date=\"2020-01-01\", sort_type=\"score\",\n",
    "                 sort=\"desc\", filename=\"phr4r.csv\",\n",
    "                 fields=[\"id\",\"title\",\"selftext\",\"score\",\"num_comments\",\"created_utc\"]\n",
    "                 ):\n",
    "        self.sub = sub\n",
    "        self.start_date = dt.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        self.end_date = dt.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        self.sort_type = sort_type\n",
    "        self.sort = sort\n",
    "        self.fields = fields\n",
    "        self.reddit_writer = RedditCsvWriter(filename)\n",
    "        self.url = \"https://api.pushshift.io/reddit/submission/search/\"\n",
    "        \n",
    "    def to_utc(self, date):\n",
    "        return int(date.replace(tzinfo=dt.timezone.utc).timestamp())\n",
    "    \n",
    "    def to_readable_date(self, timestamp):\n",
    "        return dt.datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    def get_posts(self):\n",
    "        date_range = (pd.date_range(self.start_date, \n",
    "                                    periods=(self.end_date - self.start_date).days)\n",
    "                      .tolist())\n",
    "        print(date_range)\n",
    "        for i, s_date in enumerate(date_range):\n",
    "            if i != len(date_range)-1:\n",
    "                e_date = date_range[i+1]\n",
    "                r = requests.get(url = self.url, params={\n",
    "                    'after': self.to_utc(s_date),\n",
    "                    'before': self.to_utc(e_date),\n",
    "                    'sort_type': self.sort_type,\n",
    "                    'sort': self.sort,\n",
    "                    'subreddit': self.sub,\n",
    "                    'fields': self.fields,\n",
    "                    \"size\": 500\n",
    "                })\n",
    "                \n",
    "                print(f\"Doing {s_date.strftime('%Y-%m-%d')} to {e_date.strftime('%Y-%m-%d')}\")\n",
    "                if r.status_code == 200:\n",
    "                    self.reddit_writer.write_submissions(r.json())\n",
    "                    print(\"=====Done\")\n",
    "                else:\n",
    "                    print(\"=====Skipped\")\n",
    "                time.sleep(1)\n",
    "\n",
    "reddit_crawler = SubRedditCrawler(\"phr4r\", start_date=\"2020-03-01\", end_date=\"2020-03-04\")        \n",
    "reddit_crawler.get_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"phr4r.csv\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
